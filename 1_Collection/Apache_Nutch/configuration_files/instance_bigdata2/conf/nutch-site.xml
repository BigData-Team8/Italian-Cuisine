<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>
  <name>http.agent.name</name>
  <value>BigData project crawler</value>
  <description>HTTP 'User-Agent' request header. MUST NOT be empty -
  please set this to a single word uniquely related to your organization.

  NOTE: You should also check other related properties:

    http.robots.agents
    http.agent.description
    http.agent.url
    http.agent.email
    http.agent.version

  and set their values appropriately.

  </description>
</property>

<!--
    https://github.com/apache/nutch/tree/master/src/plugin/index-links
    index-links plugin to extract inLinks, outLinks
--> 
<property>
  <name>plugin.includes</name>
  <value>indexer-kafka|parse-rawhtml|index-rawhtml|protocol-http|urlfilter-(regex|validator)|parse-(html|tika|metatags)|index-(basic|anchor|metadata)|indexer-solr|scoring-opic|urlnormalizer-(pass|regex|basic)</value>
  <description>Regular expression naming plugin directory names to
  include.  Any plugin not matching this expression is excluded.
  By default Nutch includes plugins to crawl HTML and various other
  document formats via HTTP/HTTPS and indexing the crawled content
  into Solr.  More plugins are available to support more indexing
  backends, to fetch ftp:// and file:// URLs, for focused crawling,
  and many other use cases.
  </description>
</property>

<!-- Used only if plugin parse-metatags is enabled. -->
<property>
  <name>metatags.names</name>
  <value>description,keywords</value>
  <description> Names of the metatags to extract, separated by ','.
  Use '*' to extract all metatags. Prefixes the names with 'metatag.'
  in the parse-metadata. For instance to index description and keywords,
  you need to activate the plugin index-metadata and set the value of the
  parameter 'index.parse.md' to 'metatag.description,metatag.keywords'.
  </description>
</property>

<!-- https://cwiki.apache.org/confluence/display/NUTCH/IndexMetatags -->
<!-- /opt/solr/server/solr/configsets/nutch/conf/schema.xml -->
<property>
  <name>index.parse.md</name>
  <value>metatag.description,metatag.keywords</value>
  <description>
  Comma-separated list of keys to be taken from the parse metadata to generate fields.
  Can be used e.g. for 'description' or 'keywords' provided that these values are generated
  by a parser (see parse-metatags plugin)
  </description>
</property>

<property>
  <name>fetcher.server.delay</name>
  <value>0.5</value>
  <description>The number of seconds the fetcher will delay between
  successive requests to the same server. Note that this might get
  overridden by a Crawl-Delay from a robots.txt and is used ONLY if
  fetcher.threads.per.queue is set to 1.
   </description>
</property>
  
<property>
  <name>fetcher.threads.fetch</name>
  <value>20</value>
  <description>The number of FetcherThreads the fetcher should use.
  This is also determines the maximum number of requests that are
  made at once (each FetcherThread handles one connection). The total
  number of threads running in distributed mode will be the number of
  fetcher threads * number of nodes as fetcher has one map task per node.
  </description>
</property>

<property>
  <name>fetcher.threads.per.queue</name>
  <value>1</value>
  <description>This number is the maximum number of threads that
    should be allowed to access a queue at one time. Setting it to
    a value > 1 will cause the Crawl-Delay value from robots.txt to
    be ignored and the value of fetcher.server.min.delay to be used
    as a delay between successive requests to the same server instead
    of fetcher.server.delay.
   </description>
</property>

</configuration>


